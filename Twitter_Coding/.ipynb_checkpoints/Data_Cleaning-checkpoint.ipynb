{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "375201c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/caleb/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc7873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cb7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Column\n",
    "df.rename(columns = {\"Unnamed: 0\": \"index\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5941d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "df.drop(columns = [\"author_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78afb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing value in Column[\"author_description\", \"author_location\"]\n",
    "df['author_description'].fillna('Unknown', inplace=True)\n",
    "df['author_location'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5da6cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                 0\n",
       "created_at            0\n",
       "username              0\n",
       "author_description    0\n",
       "author_location       0\n",
       "text                  0\n",
       "retweets              0\n",
       "replies               0\n",
       "likes                 0\n",
       "quote_count           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check these two columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4137bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 'edited' column that is equivalent to 'text' column\n",
    "df['edited'] = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da910aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercasing all letters\n",
    "df[\"edited\"] = df[\"edited\"].str.lower()\n",
    "#Removing hashtags and mentions\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(\"@[A-Za-z0-9_]+\",\"\", regex=True)\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(\"#[A-Za-z0-9_]+\",\"\", regex=True)\n",
    "#Removing links\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(r\"http\\S+\", \"\", regex=True)\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(r\"www.\\S+\", \"\", regex=True)\n",
    "#Removing punctuations\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(\"[()!?]\", \" \", regex=True)\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(\"\\[.*?\\]\", \" \", regex=True)\n",
    "#Filtering non-alphanumeric characters\n",
    "df[\"edited\"] = df[\"edited\"].str.replace(\"[^a-z0-9]\",\" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe464f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Dataframe that only contains the 'text' column and 'edited' column for comparsion. \n",
    "tmp = df[[\"text\", \"edited\"]].copy()\n",
    "# #Drop the duplicated rows\n",
    "# tmp.drop_duplicates(inplace=True, ignore_index=True)\n",
    "tmp.to_csv(\"tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d2c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Dataframe that contains only the 'text_edited' column and transfer it into csv file.\n",
    "text_only_tokenize = df[[\"edited\"]].copy()\n",
    "text_only = df[[\"edited\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a392fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "text_only_tokenize[\"edited\"] = text_only[\"edited\"].str.split()\n",
    "text_only_tokenize.to_csv('text_only_tokenize.csv')\n",
    "\n",
    "#regular style\n",
    "text_only.to_csv(\"text_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40f4edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The the version of tweets without stopwords.\n",
    "#Stopwords Removeral\n",
    "stop = stopwords.words('english')\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "text_only['tweet_without_stopwords'] = text_only['edited'].str.replace(pat, '',regex=True)\n",
    "text_only['tweet_without_stopwords'] = text_only['tweet_without_stopwords'].str.replace(r'\\s+', ' ', regex=True)\n",
    "text_only.to_csv(\"tweets_without_stopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd39d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
