{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545f33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import time\n",
    "from twitter_auth import bearer_token\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c5a544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a39e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55f368",
   "metadata": {},
   "source": [
    "# Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8984b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c027484",
   "metadata": {},
   "source": [
    "# Full Archive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bd1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6cf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Query \n",
    "\n",
    "#<company name> ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc959a5",
   "metadata": {},
   "source": [
    "### Heavy equipment company name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65f4f5",
   "metadata": {},
   "source": [
    "### Anhui Jianghuai Automobile Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b93bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1559439966958149633', 'oldest_id': '935715795744772098', 'result_count': 30}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Anhui Jianghuai Automobile Co. Ltd) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "937d9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_1 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999401d",
   "metadata": {},
   "source": [
    "### Anhui Quanchai Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805b21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1489933948369129472', 'oldest_id': '879324598218752001', 'result_count': 12}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Anhui Quanchai Ltd) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03012c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_2 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00686a",
   "metadata": {},
   "source": [
    "### Arctic Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087d0ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result_count': 0, 'next_token': 'b26v89c19zqg8o3fosqspd07hgm3uarg0yxnkx7rvf2pp'}\n",
      "{'newest_id': '1251072376005185536', 'oldest_id': '1251072376005185536', 'result_count': 1, 'next_token': 'b26v89c19zqg8o3fnm313s86qgwcbptfhhchewcdgmkcd'}\n",
      "{'newest_id': '1138382130080362499', 'oldest_id': '928945019876241408', 'result_count': 13}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Arctic Cat) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3adbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets[1:3]:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_3 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7ec9d",
   "metadata": {},
   "source": [
    "### Ashok Leyland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7588f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1561447115272110080', 'oldest_id': '1155815267244507136', 'result_count': 92, 'next_token': 'b26v89c19zqg8o3fnlx0pmt6di6ga14w86jtwv1uz79tp'}\n",
      "{'newest_id': '1134418900362227712', 'oldest_id': '827050981330472960', 'result_count': 76}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Ashok Leyland) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ef8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_4 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082cbfde",
   "metadata": {},
   "source": [
    "### Audi AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c953fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1537385131014385664', 'oldest_id': '1202649275806736386', 'result_count': 21, 'next_token': 'b26v89c19zqg8o3fnlx2tvwp2f1mgclmlk4ul2p2rxj7h'}\n",
      "{'newest_id': '1138690127008546817', 'oldest_id': '976488156647317504', 'result_count': 21}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Audi AG) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a12dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_5 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e48ba",
   "metadata": {},
   "source": [
    "### Beijing Foton Cummins Engine Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25ed46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1493084407468802050', 'oldest_id': '875113323490050048', 'result_count': 7}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Beijing Foton Cummins Engine) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173dfb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_6 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9ff53",
   "metadata": {},
   "source": [
    "### Beiqi Foton Environmental Protection Power Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1a1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1540856880653684736', 'oldest_id': '920912790013038593', 'result_count': 34}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Beiqi Foton) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcf653e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_7 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70741bd2",
   "metadata": {},
   "source": [
    "### Briggs & Stratton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54f6290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1562335449984933890', 'oldest_id': '1145858139209838593', 'result_count': 95, 'next_token': 'b26v89c19zqg8o3fnlx0pmt6di6ga14w88qqrbz183n25'}\n",
      "{'newest_id': '1125564422574018561', 'oldest_id': '873253642756902914', 'result_count': 29}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Briggs Stratton) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06a25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_8 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d380ec",
   "metadata": {},
   "source": [
    "### BRP-Rotax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07178182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1528127245738512390', 'oldest_id': '1234866122622750720', 'result_count': 6}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(BRP-Rotax) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9d00914",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_9 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7bcb0",
   "metadata": {},
   "source": [
    "### Caterpillar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11427a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1562335449984933890', 'oldest_id': '1314286719206789120', 'result_count': 404, 'next_token': 'b26v89c19zqg8o3fos8tmxcevrhc2hhh24j9fjn3os399'}\n",
      "{'newest_id': '1313479943939149826', 'oldest_id': '967789549354012672', 'result_count': 436, 'next_token': '1jzu9lk96gu5npw44qggnxi8erzrgq447h0k9bvfp9q5'}\n",
      "{'newest_id': '966602346837958657', 'oldest_id': '816842880371359744', 'result_count': 117}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = 'Caterpillar ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3000695",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_10 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dcdf42",
   "metadata": {},
   "source": [
    "### Changchai Co. LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4708c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1298206725661700096', 'oldest_id': '868089635259502593', 'result_count': 8}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Changchai Co Ltd) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a20227",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_11 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d829253",
   "metadata": {},
   "source": [
    "### Changchun FAW Sihuan Engine Manufacturing Co. Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0eb9a8",
   "metadata": {},
   "source": [
    "### Chery Automobile Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a50620fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564524321082589184', 'oldest_id': '822396770646753280', 'result_count': 288}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Chery International) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5daad40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_12 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061bf81",
   "metadata": {},
   "source": [
    "### Chongqing Huansong Industries Co. Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f760e",
   "metadata": {},
   "source": [
    "### CNH Industrial (India) Private Limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f7cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1540791156736401408', 'oldest_id': '1060472437543002118', 'result_count': 112, 'next_token': 'b26v89c19zqg8o3fn0pn07y8163rvczabqt5j612w1rb1'}\n",
      "{'newest_id': '1055475256801009664', 'oldest_id': '831593013818204160', 'result_count': 19}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(CNH Industrial) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94100cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_13 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151eb78",
   "metadata": {},
   "source": [
    "### Cummins Engine Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09088af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563539372024049665', 'oldest_id': '1049465342089682944', 'result_count': 494, 'next_token': 'b26v89c19zqg8o3fn0mohuwha84hbh55tokqdxdjvn531'}\n",
      "{'newest_id': '1049399243792760832', 'oldest_id': '817140903898976257', 'result_count': 20}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Cummins Inc.) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e273f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_14 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f26a0e",
   "metadata": {},
   "source": [
    "### Cummins Kama "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43adff2a",
   "metadata": {},
   "source": [
    "### Daedong Industrial Co. LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9de03ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1507620975382343684', 'oldest_id': '864874514068500486', 'result_count': 61}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Daedong Industrial) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7c11ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_15 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b6a5a",
   "metadata": {},
   "source": [
    "### DAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15b953e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1557038305883078656', 'oldest_id': '1545158050176270336', 'result_count': 3, 'next_token': 'b26v89c19zqg8o3fpywl80yqe3h0iisp54mimh1ygqr99'}\n",
      "{'newest_id': '1517065659204657152', 'oldest_id': '1517056786624352257', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpe45ym1e2g8jjr46l8e6gbhctiwsd'}\n",
      "{'newest_id': '1475132724797231110', 'oldest_id': '1453437747193073665', 'result_count': 5, 'next_token': 'b26v89c19zqg8o3fpdp8rhmn8ke2rwera5n426g9shbp9'}\n",
      "{'newest_id': '1420468078236798980', 'oldest_id': '1387413950095048713', 'result_count': 7, 'next_token': 'b26v89c19zqg8o3fostsh6vsa4tb7cx5dsqgs3gmdpk71'}\n",
      "{'newest_id': '1364723948030734337', 'oldest_id': '1357294616593264644', 'result_count': 2, 'next_token': 'b26v89c19zqg8o3fosevp3vmn6shlwjk7xjwrgm6yubnh'}\n",
      "{'newest_id': '1310569364412928002', 'oldest_id': '1296072201041514496', 'result_count': 2, 'next_token': 'b26v89c19zqg8o3fo7meckbcnh420r764u06623hkwcxp'}\n",
      "{'newest_id': '1290380687971954688', 'oldest_id': '1282639163775475712', 'result_count': 2, 'next_token': 'b26v89c19zqg8o3fo74fooxxy7dk0zlo49p5y0duwgx31'}\n",
      "{'newest_id': '1231174387304411137', 'oldest_id': '1140707068304863232', 'result_count': 8, 'next_token': 'b26v89c19zqg8o3fnlu1sl700p1s4xfh8vrr2ygqcu7p9'}\n",
      "{'newest_id': '1131575022487654400', 'oldest_id': '1096002328065302528', 'result_count': 9, 'next_token': 'b26v89c19zqg8o3fn0ylwqho1asgx9nkud5s5jhqpib25'}\n",
      "{'newest_id': '1082626905172365313', 'oldest_id': '1042329166497148928', 'result_count': 6, 'next_token': 'b26v89c19zqg8o3fn0jnvpqbmmkv6eyofet0k45qsx7r1'}\n",
      "{'newest_id': '1036895814772301824', 'oldest_id': '1001780892644335617', 'result_count': 2, 'next_token': '1jzu9lk96gu5npw44qf70owgcv4531pv7n4tc7q7dn5p'}\n",
      "{'newest_id': '930742006934114304', 'oldest_id': '826094480507990017', 'result_count': 18}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(DAF Trucks N.V.) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "247421de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df_16 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ea938",
   "metadata": {},
   "source": [
    "### Deere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54bb8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563545957639147520', 'oldest_id': '1355907455855812612', 'result_count': 155, 'next_token': 'b26v89c19zqg8o3fosksawy6fctsz8ynh82wr4gny4ccd'}\n",
      "{'newest_id': '1352013290856206346', 'oldest_id': '819251662183342080', 'result_count': 119}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(John Deere) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e52c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_17 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a827c",
   "metadata": {},
   "source": [
    "### Detroit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69004f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565122286063083522', 'oldest_id': '1405620232316612608', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fpdg90yl1dbpoprm1sp9ntnko3uuf1'}\n",
      "{'newest_id': '1405495541128220673', 'oldest_id': '1187540979101908992', 'result_count': 422, 'next_token': 'b26v89c19zqg8o3fnm912yetty2es1s6wm1glw46qukql'}\n",
      "{'newest_id': '1186143381950357504', 'oldest_id': '956866212448952321', 'result_count': 491, 'next_token': '1jzu9lk96gu5npw44ng9utvfagu3me6qc6fyo5unv6gt'}\n",
      "{'newest_id': '956727162530357249', 'oldest_id': '818784357896704000', 'result_count': 499, 'next_token': '1jzu9lk96gu5npw3j13oramlbfnnrdlpu1s3ct12lqpp'}\n",
      "{'newest_id': '818780784677060608', 'oldest_id': '816370230914125826', 'result_count': 10}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Detroit) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9f4f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_18 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eafb530",
   "metadata": {},
   "source": [
    "### Deutz AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82d0d00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1475559192111030280', 'oldest_id': '1014406257933860864', 'result_count': 19}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Deutz AG) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9be24e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_19 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f59987",
   "metadata": {},
   "source": [
    "### DMAX Ltd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9385b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564385524051169280', 'oldest_id': '836605142778572800', 'result_count': 114}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(DMAX Ltd.) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6ea52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_20 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe0d34",
   "metadata": {},
   "source": [
    "### Dongfeng Chaoyang Diesel Engine Co."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58865c7",
   "metadata": {},
   "source": [
    "### Dongfeng Commercial Vehicle Engine Plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64efbf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1560182183888830466', 'oldest_id': '816855786420834304', 'result_count': 79}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Dongfeng Commercial Vehicle) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9e10c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_21 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab92ef",
   "metadata": {},
   "source": [
    "### Dongfeng Cummins Engine Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be396905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1516600990161522692', 'oldest_id': '1283656724323287041', 'result_count': 9}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Dongfeng Cummins Engine Co. Ltd) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70c60eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_22 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1caa6e",
   "metadata": {},
   "source": [
    "### Dongfeng Light Engine Co.,Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72caab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result_count': 0, 'next_token': 'b26v89c19zqg8o3fpyqlo6s7tqvz2401uxrtv4hqod7jx'}\n",
      "{'result_count': 0, 'next_token': 'b26v89c19zqg8o3fostrmxt836x3michjq2bb9tarhxtp'}\n",
      "{'newest_id': '1379701740409384961', 'oldest_id': '1356231236214206470', 'result_count': 2, 'next_token': 'b26v89c19zqg8o3fnmbxwipmefh6clnfk90l4vmkzo9dp'}\n",
      "{'result_count': 0, 'next_token': 'b26v89c19zqg8o3fn0jnvnoajlqctavvo3c8djkbvympp'}\n",
      "{'result_count': 0}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Dongfeng Light Engine Co.,Ltd) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ae34212",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets[2:3]:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_23 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dac99",
   "metadata": {},
   "source": [
    "### Doosan Infracore Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a23a80b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1399733476849508356', 'oldest_id': '1014406257933860864', 'result_count': 6}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Doosan Infracore) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f60ab634",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_24 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a66147",
   "metadata": {},
   "source": [
    "### Eicher Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "171e6ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1562286394311348230', 'oldest_id': '1247525028708536322', 'result_count': 8}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Eicher Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d80c4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_25 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e774e",
   "metadata": {},
   "source": [
    "### Escorts Ltd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2c527b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564142803596087296', 'oldest_id': '1044172108652322816', 'result_count': 142}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Escorts Kubota Limited) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bd4117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_26 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538c39b",
   "metadata": {},
   "source": [
    "### FAW Jiefang Engine Group-Dalian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c115b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1539495362892808193', 'oldest_id': '820986465228390402', 'result_count': 23}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(FAW Jiefang Engine) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "623df6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_27 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74663ad2",
   "metadata": {},
   "source": [
    "### FAW Jiefang Engine Group-Wuxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6a5d9",
   "metadata": {},
   "source": [
    "### Fiat Powertrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "693998ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1534092993040359424', 'oldest_id': '1048528482362413056', 'result_count': 8}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Fiat Powertrain) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b19e89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_28 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28535cf2",
   "metadata": {},
   "source": [
    "### Force Motors LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0333564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1562682954673160193', 'oldest_id': '815973727502336000', 'result_count': 496, 'next_token': '1jzu9lk96gu5npw3j12fepyaw7n5meyf2qtlvjjat7ct'}\n",
      "{'newest_id': '815792265096351744', 'oldest_id': '815791129421455360', 'result_count': 2}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Force Motors Ltd.) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "574590fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_29 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce225ed",
   "metadata": {},
   "source": [
    "### Ford Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5bc33ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565028943987724297', 'oldest_id': '1192065566388948992', 'result_count': 298, 'next_token': 'b26v89c19zqg8o3fnm912yetty2es1s6d2kcrepq3x4sd'}\n",
      "{'newest_id': '1185596079942914048', 'oldest_id': '844481120167170049', 'result_count': 106}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Ford Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce29b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_30 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213bb7b",
   "metadata": {},
   "source": [
    "### Ford Otosan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0af1fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1342470890940936192', 'oldest_id': '1334890213697605632', 'result_count': 4}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Ford Otosan) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33e61135",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets[0:1]:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_31 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa28ca1",
   "metadata": {},
   "source": [
    "### FPT Industrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bce8f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1546910328717557767', 'oldest_id': '902552192472805376', 'result_count': 113}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(FPT Industrial) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d93fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_32 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00585d9d",
   "metadata": {},
   "source": [
    "### Fujian Lijia Co. Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4129dada",
   "metadata": {},
   "source": [
    "### GM Powertrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4c3c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565122286063083522', 'oldest_id': '1486023441278976000', 'result_count': 500, 'next_token': 'b26v89c19zqg8o3fpe47mvo70owv9p6efvkjt3dp7fqt9'}\n",
      "{'newest_id': '1486023255479635972', 'oldest_id': '1429805125065977857', 'result_count': 488, 'next_token': 'b26v89c19zqg8o3fpdma9hc23dg6bgxf1l0dzdpp1ys1p'}\n",
      "{'newest_id': '1429798087749427203', 'oldest_id': '1406997878065741835', 'result_count': 489, 'next_token': 'b26v89c19zqg8o3fpdg9gan9k0uzyh00mmlgh103vdegt'}\n",
      "{'newest_id': '1406992148499730432', 'oldest_id': '1367561739726848003', 'result_count': 485, 'next_token': 'b26v89c19zqg8o3fosnu6recuyhif1abb5i66lf2s2zct'}\n",
      "{'newest_id': '1367560476301946881', 'oldest_id': '1306302176214560768', 'result_count': 483, 'next_token': 'b26v89c19zqg8o3fos5v459zkunpxx6wl8gyp8n3bkznh'}\n",
      "{'newest_id': '1306273420187893761', 'oldest_id': '1218592578431528960', 'result_count': 491, 'next_token': 'b26v89c19zqg8o3fo6yheod0406m9ny6r2w1lis3szou5'}\n",
      "{'newest_id': '1218329682766188545', 'oldest_id': '986862739858558978', 'result_count': 491, 'next_token': '1jzu9lk96gu5npw44wflixgfwjpgdgks9nmqpl8g7on1'}\n",
      "{'newest_id': '986862172750974976', 'oldest_id': '826178178557288449', 'result_count': 497, 'next_token': '1jzu9lk96gu5npw3j42lzbab270dvwc249lyt20nu1dp'}\n",
      "{'newest_id': '826167004360871936', 'oldest_id': '826098817355436032', 'result_count': 156}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(General Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3087399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_33 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b91150",
   "metadata": {},
   "source": [
    "### GM-Brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc1a3f",
   "metadata": {},
   "source": [
    "### Great Wall Motor Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66c8c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1561477727534075904', 'oldest_id': '1218945996073422848', 'result_count': 52, 'next_token': 'b26v89c19zqg8o3fo6vf3yvte660jbuomrq430larrerh'}\n",
      "{'newest_id': '1197798347152617472', 'oldest_id': '967125867196534784', 'result_count': 58}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Great Wall Motor) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d10081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_34 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e3fb2",
   "metadata": {},
   "source": [
    "### Guangxi Cummins Industrial Power Co.,Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19a102",
   "metadata": {},
   "source": [
    "### Hangzhou Auto Engine Factory-CNHTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6033cbe",
   "metadata": {},
   "source": [
    "### Hino Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "270d8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1555377353634766848', 'oldest_id': '903069500261539840', 'result_count': 155}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Hino Trucks) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d24417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_35 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b65f06",
   "metadata": {},
   "source": [
    "### Honda Motor Company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac162f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565054780174700549', 'oldest_id': '1260217627835760641', 'result_count': 239, 'next_token': 'b26v89c19zqg8o3fo7aeeear2xuuhce2yjxceqgp5hn5p'}\n",
      "{'newest_id': '1250698600797163520', 'oldest_id': '826120456595927040', 'result_count': 139}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Honda Motor) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f26d04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_36 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb2b98",
   "metadata": {},
   "source": [
    "### Hyundai Motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cebf8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564956582491951105', 'oldest_id': '1435194618786635779', 'result_count': 499, 'next_token': 'b26v89c19zqg8o3fpdp8cc33iedjnn36sbdhxyuiuzr0d'}\n",
      "{'newest_id': '1435192230738681860', 'oldest_id': '1364633690907631619', 'result_count': 473, 'next_token': 'b26v89c19zqg8o3fosnsxcocyvd0hrfuljifufemia3ct'}\n",
      "{'newest_id': '1364629466392260611', 'oldest_id': '1281359351110930434', 'result_count': 483, 'next_token': 'b26v89c19zqg8o3fo7jcvp14ydj76agto3ibzhkgpdo59'}\n",
      "{'newest_id': '1280770298535706624', 'oldest_id': '1043253807499554817', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fn0mlysz2lsnehg1r9gfyu9xqh26pp'}\n",
      "{'newest_id': '1043127196062298118', 'oldest_id': '817132490305454080', 'result_count': 309}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Hyundai Motor) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f279e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_37 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a39696",
   "metadata": {},
   "source": [
    "### Ishikawajima-Shibaura Machinery Co. LTD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110edbf",
   "metadata": {},
   "source": [
    "### Isuzu Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "15938d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563543858239090688', 'oldest_id': '840089443398643713', 'result_count': 41}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Isuzu Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1f0a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_38 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f0447",
   "metadata": {},
   "source": [
    "### JAC-Cummins Engine Company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a1d4c",
   "metadata": {},
   "source": [
    "### JCB Power Systems LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c45288dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1551955006735228930', 'oldest_id': '828970761167728640', 'result_count': 94}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(JCB Power Systems) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "13dfe1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_39 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe4123",
   "metadata": {},
   "source": [
    "### Jiangsu Jianghuai Engine Co., Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be043006",
   "metadata": {},
   "source": [
    "### JIANGXI ISUZU MOTORS CO.,LTD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262cbb",
   "metadata": {},
   "source": [
    "### Jiangxi Jiangling Motors Co., Ltd.  (JMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e076e",
   "metadata": {},
   "source": [
    "### Kamaz Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae8d326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1557110425447272449', 'oldest_id': '822468610987671552', 'result_count': 39}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Kamaz) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0603323",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_40 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b581f3",
   "metadata": {},
   "source": [
    "### Kawasaki Heavy Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d24f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1515623433945718788', 'oldest_id': '959068197633761282', 'result_count': 78}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Kawasaki Heavy Industries) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aaa5b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_41 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e7dc09",
   "metadata": {},
   "source": [
    "### Kia Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc6f43ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1527195948417306625', 'oldest_id': '849306808145653760', 'result_count': 146}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Kia Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b5b7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_42 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e622db",
   "metadata": {},
   "source": [
    "### Kubota Corporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c4f36",
   "metadata": {},
   "source": [
    "### Kunming Yunnei Power Company LTD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e789d",
   "metadata": {},
   "source": [
    "### Loncin Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a8c364",
   "metadata": {},
   "source": [
    "### Mahindra & Mahindra Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e207655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564646197767200769', 'oldest_id': '1299341154165514242', 'result_count': 477, 'next_token': 'b26v89c19zqg8o3fo7mg0txk8gkvjkp21anvmopbvs7zx'}\n",
      "{'newest_id': '1298314693333757954', 'oldest_id': '818537574570590208', 'result_count': 455}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Mahindra Mahindra) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a25820b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_43 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa2209",
   "metadata": {},
   "source": [
    "### MAN Energy Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47fba48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1555105981096411137', 'oldest_id': '1387789481579794438', 'result_count': 21, 'next_token': 'b26v89c19zqg8o3fosqspd07hgm3uarfx62fv03dox4zh'}\n",
      "{'newest_id': '1278946720873885697', 'oldest_id': '1126398935017447424', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fn0sl3jq6cjx3pf9frkhwuneafkpdp'}\n",
      "{'newest_id': '1037626767027171328', 'oldest_id': '958017459516297216', 'result_count': 8}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(MAN Energy Solutions) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "602af252",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_44 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aad8e6",
   "metadata": {},
   "source": [
    "### MAN Latin America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "194009bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1400466690022920217', 'oldest_id': '1400466690022920217', 'result_count': 1, 'next_token': 'b26v89c19zqg8o3fosksq0dl4d7rrr57uhvqtasumuqv1'}\n",
      "{'newest_id': '1173719178236366853', 'oldest_id': '1173719178236366853', 'result_count': 1, 'next_token': '1jzu9lk96gu5npw44ze3turtwvht90tmkzvtu85mpi7x'}\n",
      "{'result_count': 0}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(MAN Latin America) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34291102",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets[0:2]:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_45 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd583ea",
   "metadata": {},
   "source": [
    "### Maruti Suzuki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f1d6be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564149801809223681', 'oldest_id': '835205753589936128', 'result_count': 349}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Maruti Suzuki) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2fcfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_46 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5e139",
   "metadata": {},
   "source": [
    "### Mazda Motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3cc07d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563949533746171904', 'oldest_id': '923480976147337217', 'result_count': 120}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Mazda Motor) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f675c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_47 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1255a4",
   "metadata": {},
   "source": [
    "### Mercedes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4de373b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565074535246082048', 'oldest_id': '1526577590433107968', 'result_count': 497, 'next_token': 'b26v89c19zqg8o3fpywnbmod9yr4cr1fd8bimxhak9q4d'}\n",
      "{'newest_id': '1526576075341438976', 'oldest_id': '1502513351515062278', 'result_count': 498, 'next_token': 'b26v89c19zqg8o3fpyqm384eknx2y4gqoggyckkbyhm65'}\n",
      "{'newest_id': '1502364995450859521', 'oldest_id': '1456999921014517774', 'result_count': 490, 'next_token': 'b26v89c19zqg8o3fpdv8bqt8y5hfucqktav41kv6icscd'}\n",
      "{'newest_id': '1456943437891129344', 'oldest_id': '1418183556883492865', 'result_count': 493, 'next_token': 'b26v89c19zqg8o3fpdja20u8b6hz178pvqdwpk265pf25'}\n",
      "{'newest_id': '1418181845225594885', 'oldest_id': '1375412415840522240', 'result_count': 483, 'next_token': 'b26v89c19zqg8o3fosqt4a1g13gtf335j0ttveltayfel'}\n",
      "{'newest_id': '1375411037084774400', 'oldest_id': '1310713370358812675', 'result_count': 471, 'next_token': 'b26v89c19zqg8o3fos8sdc6qk0rirl54b2jojd7v0x8jh'}\n",
      "{'newest_id': '1310700828005732352', 'oldest_id': '1228353225268617217', 'result_count': 492, 'next_token': 'b26v89c19zqg8o3fo71h6g3jrckos4obarp2jii4wxksd'}\n",
      "{'newest_id': '1228298671604879360', 'oldest_id': '1165190321187082240', 'result_count': 491, 'next_token': 'b26v89c19zqg8o3fnm30omo17udmkr931znotr83kivlp'}\n",
      "{'newest_id': '1164834473596219394', 'oldest_id': '1099561069209628672', 'result_count': 497, 'next_token': 'b26v89c19zqg8o3fn11ndd76kk4j2tzd8fhi94sb5pn5p'}\n",
      "{'newest_id': '1099394022257369096', 'oldest_id': '1048645351832526849', 'result_count': 494, 'next_token': 'b26v89c19zqg8o3fn0mo2tje2zaqdi738jo3u1m60127x'}\n",
      "{'newest_id': '1048622307160338435', 'oldest_id': '1018818978414759937', 'result_count': 497, 'next_token': 'b26v89c19zqg8o3fn0dor9ocyaqrp20fy8cgwb4sq8br1'}\n",
      "{'newest_id': '1018783321105551360', 'oldest_id': '968538802892496897', 'result_count': 499, 'next_token': '1jzu9lk96gu5npw44qgvvnvletf9qe0v6q7jjxsci5bx'}\n",
      "{'newest_id': '968302291097915393', 'oldest_id': '912107437880115200', 'result_count': 500, 'next_token': '1jzu9lk96gu5npw44bfh9afru7kmig9qwmfpfd3i65q5'}\n",
      "{'newest_id': '912107415327395841', 'oldest_id': '905092438641045505', 'result_count': 495, 'next_token': '1jzu9lk96gu5npw448gys117poa5k1gf4kqdttr8i071'}\n",
      "{'newest_id': '905091141581684736', 'oldest_id': '815974239878737922', 'result_count': 487}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Mercedes) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "66ee294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_48 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaba6c9",
   "metadata": {},
   "source": [
    "### Millat Tractors Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1aaeb",
   "metadata": {},
   "source": [
    "### Minsk Motor Works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041060f7",
   "metadata": {},
   "source": [
    "### Mitsubishi Fuso Truck and Bus Corporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66243d63",
   "metadata": {},
   "source": [
    "### Mitsubishi Heavy Industries Engine & Turbocharger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aeddb4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1167330822749392896', 'oldest_id': '1156029664814518275', 'result_count': 11}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Mitsubishi Heavy Industries Engine Turbocharger) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4cda16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_49 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e075acd",
   "metadata": {},
   "source": [
    "### Mitsubishi Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ccea17f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1552820172343627778', 'oldest_id': '900073201652432896', 'result_count': 64}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Mitsubishi Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e350ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_50 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ed9de",
   "metadata": {},
   "source": [
    "### NAVECO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db08f421",
   "metadata": {},
   "source": [
    "### Nissan Motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c038c61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564896222070063105', 'oldest_id': '862305766077861888', 'result_count': 342}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Nissan Motor) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7769e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_51 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd53ff",
   "metadata": {},
   "source": [
    "### Oriental Shineray Holdings Limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1050ff",
   "metadata": {},
   "source": [
    "### Perkins Engines Company Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b8273",
   "metadata": {},
   "source": [
    "### Polaris Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99970670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1532066721334317057', 'oldest_id': '1369281179980079105', 'result_count': 4}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Polaris Inc.) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a85f9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_52 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c6fbf",
   "metadata": {},
   "source": [
    "### PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88e83b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564711060946313216', 'oldest_id': '1325127141898514432', 'result_count': 260, 'next_token': 'b26v89c19zqg8o3fosbttwtxffmfwhnxblkbkkfttvjp9'}\n",
      "{'newest_id': '1324406015132078082', 'oldest_id': '1100451425677729793', 'result_count': 496, 'next_token': 'b26v89c19zqg8o3fnlkzxos4l2ljbpnzv04emqagr5egt'}\n",
      "{'newest_id': '1100420233443983360', 'oldest_id': '826897523012939776', 'result_count': 237}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(PSA) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cae8afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_53 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4803103",
   "metadata": {},
   "source": [
    "### PT Mitsubishi Krama Yudha Motor and Manufacturing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb37a9c",
   "metadata": {},
   "source": [
    "### Qingling Motors Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d611e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563543858239090688', 'oldest_id': '1382252295006474240', 'result_count': 38}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Qingling Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ff07e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_54 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a139b",
   "metadata": {},
   "source": [
    "### Renault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aa87f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564972485388427265', 'oldest_id': '1445988007773888512', 'result_count': 494, 'next_token': 'b26v89c19zqg8o3fpds84p5t4vqcjq9gt60ti1fvmipa5'}\n",
      "{'newest_id': '1445950717554946051', 'oldest_id': '1408347094423846913', 'result_count': 484, 'next_token': 'b26v89c19zqg8o3fpdgaa91ajyiiyombgrv5ze8s8r0jh'}\n",
      "{'newest_id': '1408341368443920384', 'oldest_id': '1333791243873120256', 'result_count': 497, 'next_token': 'b26v89c19zqg8o3foset6l5cnzyuhdzd8ri2a8v7c0ccd'}\n",
      "{'newest_id': '1332915934693007361', 'oldest_id': '1215324115449602050', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fo6yg537mm70yi42d3bzjalbi7fwcd'}\n",
      "{'newest_id': '1215302257081749506', 'oldest_id': '1123283596243013634', 'result_count': 493, 'next_token': 'b26v89c19zqg8o3fnlr0qtfsmbxih3af7ub6y9joaflh9'}\n",
      "{'newest_id': '1123283154998104066', 'oldest_id': '994980532122476544', 'result_count': 496, 'next_token': '1jzu9lk96gu5npw44zej5w3b5f5zfca97pqaai9vehrx'}\n",
      "{'newest_id': '994963170304249856', 'oldest_id': '844459932988719105', 'result_count': 497, 'next_token': '1jzu9lk96gu5npw3ja1bmjdi3bmj24fhd3ra2k5hamil'}\n",
      "{'newest_id': '844456870182096896', 'oldest_id': '816136812582182912', 'result_count': 26}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Renault) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5829a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_55 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0098d",
   "metadata": {},
   "source": [
    "### Renault Nissan Automotive India PVT Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a1d3055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1489251834208219142', 'oldest_id': '953004380143476736', 'result_count': 9}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Renault Nissan Automotive) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "49464180",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_56 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38398569",
   "metadata": {},
   "source": [
    "### SAIC Fiat Powertrain Hongyan Co. Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac81675",
   "metadata": {},
   "source": [
    "### Suzuki (Same as above - Maruti Suzuki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604667e8",
   "metadata": {},
   "source": [
    "### Swaraj Engines Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e7555",
   "metadata": {},
   "source": [
    "### TAFE (Tractor and Farm Equipment Ltd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "85730890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1527382674909712392', 'oldest_id': '956401619133874177', 'result_count': 9}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Tractor Farm Equipment) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "01d00e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_57 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a6320",
   "metadata": {},
   "source": [
    "### Tata Cummins (Same as above - Cummins Inc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a4926",
   "metadata": {},
   "source": [
    "### Tata Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6456bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1561055384328015872', 'oldest_id': '1285183476258357248', 'result_count': 487, 'next_token': 'b26v89c19zqg8o3fo7jek78cg47o6499l9xknr1wh7bst'}\n",
      "{'newest_id': '1282666772697669632', 'oldest_id': '824187308698116098', 'result_count': 355}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Tata Motors) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d48f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_58 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520e0ef",
   "metadata": {},
   "source": [
    "### Tianjin Lovol Engines Co. Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ae812",
   "metadata": {},
   "source": [
    "### Toyota Motor Corporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9756ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1562828716618633216', 'oldest_id': '921378498257678336', 'result_count': 227}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Toyota Motor Corporation) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "90f8e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_59 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafe157",
   "metadata": {},
   "source": [
    "### Turk Traktor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ff118",
   "metadata": {},
   "source": [
    "### UD Trucks Corporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b92d6",
   "metadata": {},
   "source": [
    "### VM Motori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654ecbd",
   "metadata": {},
   "source": [
    "### Volkswagen AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25ddea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564912731542675456', 'oldest_id': '859732109908377603', 'result_count': 184}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Volkswagen AG) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "027316bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_60 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8d075",
   "metadata": {},
   "source": [
    "### Volvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a0548c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565034527738810368', 'oldest_id': '1539026840379064327', 'result_count': 499, 'next_token': 'b26v89c19zqg8o3fpyzocou9d1x3xf4b808ubhhdxt8xp'}\n",
      "{'newest_id': '1539026837728288769', 'oldest_id': '1500035166340882433', 'result_count': 500, 'next_token': 'b26v89c19zqg8o3fpyql8m9hnron3el9x4to4xmwpy7i5'}\n",
      "{'newest_id': '1499917147014848512', 'oldest_id': '1436382038932733953', 'result_count': 492, 'next_token': 'b26v89c19zqg8o3fpdp8rly6umed341k7jeis1nlm7c71'}\n",
      "{'newest_id': '1436378442724003899', 'oldest_id': '1391481835230728197', 'result_count': 485, 'next_token': 'b26v89c19zqg8o3foswqzfq5yszs2uyhkegnvkfsbg1od'}\n",
      "{'newest_id': '1391450345121980420', 'oldest_id': '1380655466078998536', 'result_count': 480, 'next_token': 'b26v89c19zqg8o3fostqsibl2yli41i9pki1jrj68n1bx'}\n",
      "{'newest_id': '1380440359113744385', 'oldest_id': '1323416270595788800', 'result_count': 484, 'next_token': 'b26v89c19zqg8o3fosbteina1yawfx6iqkofl2lzqx6d9'}\n",
      "{'newest_id': '1323368544432652288', 'oldest_id': '1253325283811188744', 'result_count': 487, 'next_token': 'b26v89c19zqg8o3fo7aeec4j2h7dlg36w4w6my8lpz5od'}\n",
      "{'newest_id': '1253322832286711808', 'oldest_id': '1209684239316344832', 'result_count': 494, 'next_token': 'b26v89c19zqg8o3fo6vi2026erjc59x9u07ggny46wad9'}\n",
      "{'newest_id': '1209161642354913281', 'oldest_id': '1128742983413719040', 'result_count': 496, 'next_token': 'b26v89c19zqg8o3fnlr2uw3xr2go3h9kbiebg3g4mjq0t'}\n",
      "{'newest_id': '1128723991735218176', 'oldest_id': '1021744325548486656', 'result_count': 493, 'next_token': 'b26v89c19zqg8o3fn0gll0c4myyybv4a4r013je5fw8l9'}\n",
      "{'newest_id': '1021726745853157376', 'oldest_id': '958626057636151296', 'result_count': 490, 'next_token': '1jzu9lk96gu5npw44nh41r3t0mdr5an2ccu43uw94tbx'}\n",
      "{'newest_id': '958621570133569538', 'oldest_id': '883031878944608257', 'result_count': 497, 'next_token': '1jzu9lk96gu5npw3jlzzsipbkvhwuslhp2kqc6hcittp'}\n",
      "{'newest_id': '883021927585112065', 'oldest_id': '815468140855324672', 'result_count': 405}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Volvo) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cbe338ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_61 = pd.DataFrame(result)\n",
    "#df.to_csv(\"tweet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc6c08",
   "metadata": {},
   "source": [
    "### VST Tillers Tractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5caf8",
   "metadata": {},
   "source": [
    "### Weichai Power Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d30ca0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1538971136872132610', 'oldest_id': '1032190327334023168', 'result_count': 15}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Weichai Power Engine) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7fe28a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_62 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eceb20d",
   "metadata": {},
   "source": [
    "### Weichai Power Yangzhou Diesel Engine Co. Ltd (same as above - Weichai Power Engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34a5ce",
   "metadata": {},
   "source": [
    "### Weifang Diesel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "95be84cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1183628912732934145', 'oldest_id': '1183628912732934145', 'result_count': 1}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Weifang Diesel) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "78b74bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_63 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e375c7f",
   "metadata": {},
   "source": [
    "### Yamaha Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a64e4bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1553357248038068225', 'oldest_id': '974420805995188224', 'result_count': 51}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Yamaha Motor) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "18d90345",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_64 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c4204",
   "metadata": {},
   "source": [
    "### Yanmar Co. Ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "72ae2be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1557615951184629760', 'oldest_id': '829783259185811456', 'result_count': 190}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Yanmar) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ebda6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_65 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d73962",
   "metadata": {},
   "source": [
    "### Yaroslavl Motor Works - Autodiesel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf8516",
   "metadata": {},
   "source": [
    "### Yituo Luoyang Diesel Engine Co. Ltd (YTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ef57bd",
   "metadata": {},
   "source": [
    "### Yuchai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "791c833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1547819634778599424', 'oldest_id': '925663877232283648', 'result_count': 35}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Yuchai) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29b54580",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_66 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f844d7",
   "metadata": {},
   "source": [
    "### Zhejiang CFMOTO Power Co., Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139f6e2",
   "metadata": {},
   "source": [
    "### Zhejiang Xinchai Diesel Engine Co. Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9890a6",
   "metadata": {},
   "source": [
    "### Truck companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc69a7e",
   "metadata": {},
   "source": [
    "### JCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fd1248b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563276469522268166', 'oldest_id': '1182614043594493953', 'result_count': 373, 'next_token': 'b26v89c19zqg8o3fnm8yz49aal0rll5zfdkfj9lrjvhbx'}\n",
      "{'newest_id': '1174413744543358982', 'oldest_id': '978470707955867648', 'result_count': 44}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(JCB) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1e2d273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_67 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd88db",
   "metadata": {},
   "source": [
    "### Daimler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e9bd2946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1565014062601232391', 'oldest_id': '1457205707418345476', 'result_count': 491, 'next_token': 'b26v89c19zqg8o3fpdv8qhfejygqnfbn9kqyqfa2z3kot'}\n",
      "{'newest_id': '1456909267819171845', 'oldest_id': '1394428534362357763', 'result_count': 492, 'next_token': 'b26v89c19zqg8o3fosws8wi7a0gl054kkctp96y320k1p'}\n",
      "{'newest_id': '1394324456395378691', 'oldest_id': '1387075603011153923', 'result_count': 481, 'next_token': 'b26v89c19zqg8o3fosttq8tf77zy5ncwzwd24tcch15kt'}\n",
      "{'newest_id': '1385682537348014093', 'oldest_id': '1322596123559809030', 'result_count': 479, 'next_token': 'b26v89c19zqg8o3fosbszf8rln3zg1rfgftvvcvas3531'}\n",
      "{'newest_id': '1322562378849046528', 'oldest_id': '1260090343850213376', 'result_count': 493, 'next_token': 'b26v89c19zqg8o3fo7dcwkzt8xvn9v9qn8la0z8kkkgvx'}\n",
      "{'newest_id': '1259964150668685312', 'oldest_id': '1224315556779696128', 'result_count': 493, 'next_token': 'b26v89c19zqg8o3fo71fhtml0gyrfl5b19mf3k44tbh4t'}\n",
      "{'newest_id': '1223893888772886528', 'oldest_id': '1161315191981785090', 'result_count': 491, 'next_token': 'b26v89c19zqg8o3fnm2z04fbqfzuy8so66dcd0bzfoscd'}\n",
      "{'newest_id': '1161306822852190209', 'oldest_id': '1086628503762669568', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fn0ymc2fp1g6b44ya8n7ydhv1oegsd'}\n",
      "{'newest_id': '1086625902459584512', 'oldest_id': '1072465540575313925', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fn0vkvfqh1i224h9g47frl5yfpztkt'}\n",
      "{'newest_id': '1072464812188274691', 'oldest_id': '1005460357891133440', 'result_count': 494, 'next_token': 'b26v89c19zqg8o3fn0anpobx5joh449tpi6ti6z9j3wxp'}\n",
      "{'newest_id': '1005212840922353666', 'oldest_id': '942766803129860096', 'result_count': 498, 'next_token': '1jzu9lk96gu5npw44keta86jjydjyodvc9s1799cdgu5'}\n",
      "{'newest_id': '942766022507094016', 'oldest_id': '929646463910543361', 'result_count': 493, 'next_token': '1jzu9lk96gu5npw44ei7ja24aq1tdif79n7jk4t8hbp9'}\n",
      "{'newest_id': '929646405903421440', 'oldest_id': '869573029168201728', 'result_count': 497, 'next_token': '1jzu9lk96gu5npw3jg2z8ssou1hqsyomow8udxpecrjx'}\n",
      "{'newest_id': '869513755058728960', 'oldest_id': '819543314999414784', 'result_count': 366}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Daimler) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56a38e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_68 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990db0b",
   "metadata": {},
   "source": [
    "### AGCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "35694740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1521525240312090624', 'oldest_id': '917372699856572416', 'result_count': 4}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(AGCO) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "af6bd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_69 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df290847",
   "metadata": {},
   "source": [
    "### Dongfeng Trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "80965c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1498773380836864005', 'oldest_id': '963761245999464449', 'result_count': 18}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Dongfeng Trucks) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bd5d1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_70 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ca2c8",
   "metadata": {},
   "source": [
    "### IVECO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c875a509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1558030661256093697', 'oldest_id': '1316126964705615873', 'result_count': 491, 'next_token': 'b26v89c19zqg8o3fos8uvx2c3dilw54d7c8rqjocqky2l'}\n",
      "{'newest_id': '1315910157038215169', 'oldest_id': '1043017987937120256', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fn0mlyoofbhxt1hbq8q0djgumeu459'}\n",
      "{'newest_id': '1042311165727133698', 'oldest_id': '824180025272467459', 'result_count': 306}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(IVECO) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ed6f9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_71 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f4731",
   "metadata": {},
   "source": [
    "### MAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6afbc5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1558767007725649920', 'oldest_id': '1160084522026885120', 'result_count': 35, 'next_token': 'b26v89c19zqg8o3fnlx2tvwp2f1mgckv0v1z1qxfjpev1'}\n",
      "{'newest_id': '1131092939243958273', 'oldest_id': '831608818752630785', 'result_count': 13}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Man Truck Bus) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2a348ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_72 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a24ae0",
   "metadata": {},
   "source": [
    "### Mercedes Benz (Same as above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141ab79",
   "metadata": {},
   "source": [
    "### Paccar Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba276398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1561651937484967936', 'oldest_id': '1067690486167678976', 'result_count': 14}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Paccar Inc.) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c6e2d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_73 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b418f",
   "metadata": {},
   "source": [
    "### Scania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "69bfbb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564587525032873984', 'oldest_id': '1272875062341832706', 'result_count': 495, 'next_token': 'b26v89c19zqg8o3fo7gdj9a3yn4gc3w412m592ozfbqm5'}\n",
      "{'newest_id': '1267360649530621952', 'oldest_id': '829258739198857216', 'result_count': 447}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Scania) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d44b91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_74 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba6e51",
   "metadata": {},
   "source": [
    "### Freightliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8f099dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1563065443665219584', 'oldest_id': '842509549533876224', 'result_count': 300}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Freightliner Trucks) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0a0981a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_75 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327fef3",
   "metadata": {},
   "source": [
    "### Kenworth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c1a2f3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564742572890656768', 'oldest_id': '1228101547780952064', 'result_count': 500, 'next_token': 'b26v89c19zqg8o3fo71h6bslfj6b3snrqhdb66o9p6mil'}\n",
      "{'newest_id': '1228053223350640641', 'oldest_id': '951208235893248002', 'result_count': 483, 'next_token': '1jzu9lk96gu5npw44ne5py0ahpb3ukbvf1zylrcbvtkt'}\n",
      "{'newest_id': '951205363533086720', 'oldest_id': '853983276108853248', 'result_count': 332}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Kenworth) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8a2b0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_76 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df90509",
   "metadata": {},
   "source": [
    "### Peterbilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "42a3ef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564742572890656768', 'oldest_id': '816366063050891264', 'result_count': 310}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Peterbilt) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a66d36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_77 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ea0d7",
   "metadata": {},
   "source": [
    "### Mack Trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "db6e046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1564303700553879562', 'oldest_id': '870280286084444160', 'result_count': 156}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Mack Trucks) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c832095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_78 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2738012",
   "metadata": {},
   "source": [
    "### Western Trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bedaaa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1547702707011457025', 'oldest_id': '1050208318306701312', 'result_count': 73}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Western Trucks) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cb2c7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_79 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40004eaf",
   "metadata": {},
   "source": [
    "### Navistar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8567a6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1560022219455078400', 'oldest_id': '853691006235049988', 'result_count': 378}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = '(Navistar) ((Battery electric) OR (Li-ion) OR (Lithium-ion) OR (Hydrogen Fuel Cell) OR (Fuel cells) OR (Hydrogen combusion engine) OR (Hydrogen ICE) OR (Natural Gas) OR (Compressed natural gas)) -is:retweet lang:en',\n",
    "                                 \n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2017-01-01T00:00:00Z',\n",
    "                                 end_time = '2022-08-31T23:59:59Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    tweets.append(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a18ad28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'created_at': tweet.created_at,\n",
    "                       'author_id': tweet.author_id, \n",
    "                       'username': author_info['username'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })\n",
    "df_80 = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f7d21d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the lists of data frame.\n",
    "final_df = pd.DataFrame()\n",
    "df_list = [df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10,\n",
    "          df_11, df_12, df_13, df_14, df_15, df_16, df_17, df_18, df_19, df_20,\n",
    "          df_21, df_22, df_23, df_24, df_25, df_26, df_27, df_28, df_29, df_30,\n",
    "          df_31, df_32, df_33, df_34, df_35, df_36, df_37, df_38, df_39, df_40,\n",
    "          df_41, df_42, df_43, df_44, df_45, df_46, df_47, df_48, df_49, df_50,\n",
    "          df_51, df_52, df_53, df_54, df_55, df_56, df_57, df_58, df_59, df_60,\n",
    "          df_61, df_62, df_63, df_64, df_65, df_66, df_67, df_68, df_69, df_70,\n",
    "          df_71, df_72, df_73, df_74, df_75, df_76, df_77, df_78, df_79, df_80]\n",
    "#Combine multiple data frames into one data frame.\n",
    "final_df = final_df.append(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8159185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert panda data frame into csv file.\n",
    "final_df.to_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d0b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
